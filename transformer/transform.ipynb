{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME='kiseki'\n",
    "\n",
    "qrc_line_re=re.compile(r'^\\[(\\d+),(\\d+)\\](.*)$')\n",
    "qrc_chunk_re=re.compile(r'^(.*)\\((\\d+),(\\d+)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_qrc(data):\n",
    "    INF=2147483647\n",
    "\n",
    "    out=[]\n",
    "    line_time=[]\n",
    "\n",
    "    def apply_chunk(data,time_s,dt):\n",
    "        if time_s is not None:\n",
    "            chunk_action.append([time_s,True,chunkid])\n",
    "            chunk_action.append([time_s+dt,False,chunkid])\n",
    "\n",
    "    for line_s in data.split('\\n'):\n",
    "        line=qrc_line_re.match(line_s)\n",
    "        if not line:\n",
    "            print('ignored LINE:',line_s)\n",
    "            continue\n",
    "\n",
    "        time_s,dt,content=line.groups()\n",
    "        time_s=int(time_s)\n",
    "        dt=int(dt)\n",
    "        \n",
    "        line_time.append(time_s)\n",
    "        cur_line=[] # list of [time,txt]\n",
    "\n",
    "        splited_content=content.split(')')\n",
    "        for ind,chunk_s in enumerate(splited_content):\n",
    "            chunk=qrc_chunk_re.match(chunk_s)\n",
    "            if not chunk:\n",
    "                if len(splited_content)==ind+1: # last chunk without timestamp\n",
    "                    if chunk_s:\n",
    "                        cur_line.append([INF,chunk_s])\n",
    "                else: # normal ')'\n",
    "                    cur_line[-1][1]+=chunk_s+')'\n",
    "                    #splited_content[ind+1]=chunk_s+')'+splited_content[ind+1]\n",
    "                continue\n",
    "\n",
    "            content,time_s,dt=chunk.groups()\n",
    "            time_s=int(time_s)\n",
    "            #dt=int(dt)\n",
    "            cur_line.append([time_s,content])\n",
    "            \n",
    "        out.append(cur_line)\n",
    "\n",
    "    return {\n",
    "        'lines': out,\n",
    "        'line_time': line_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignored LINE: [ti:軌跡 (轨迹)]\n",
      "ignored LINE: [ar:Roselia]\n",
      "ignored LINE: [al:Opera of the wasteland]\n",
      "ignored LINE: [by:]\n",
      "ignored LINE: [offset:0]\n",
      "ignored LINE: [kana:1き1せ(957,136)き(1093,96)111し1おり1た1き(3197,103)ょ(3301,103)く(3404,185)1ふじ1えい1りゅう1た1ろう1くつ1ひ(23951,232)も(24183,285)1ほど1むす1な(26999,248)お(27247,193)1わか1と1ぎ1つな1ため1で1あ1ひと1あゆ1かな1むね1なか1おぼ1まぶた1と1むか1 か1わら2あなた1ひとみ1き1れい1めぐ1あ1いのち1く1かえ1はじ1な1みち1ふ1む1まえ1み1めぐ1ち1きゅう2あなた1わたし1すす1にぎ1て1は な1お1きずな2あした1く1あ1まえ1ふ1ま1うたが1ほ1しょう1ひ1び1はかな1ひと1だ1ふ1かえ1やさ1み1まい1にち1たい1せつ1のこ1やわ1ここ1ち1いろ1き1れい1うた1いと1つ1あふ1だ1おも1ほし1またた1めぐ1ち1きゅう2あなた1わたし1すす1め1ざ1ば1しょ1ちが1か1け1しき1よみがえ1よみがえ1すがた1すがた1こころ1だ1つら1だれ1うそ1さと1たば1こと1ば1つた1こ1こ1あ2あなた1わたし1き1せき1ひと1わす1あつ1めぐ1ち1きゅう2あなた1わたし1すす1にぎ1て1はな1お1きずな1いく1せん1えい1えん1かさ]\n",
      "ignored LINE: \n",
      "ignored LINE: [ti:軌跡 (轨迹)]\n",
      "ignored LINE: [ar:Roselia]\n",
      "ignored LINE: [al:Opera of the wasteland]\n",
      "ignored LINE: [by:]\n",
      "ignored LINE: [offset:0]\n",
      "ignored LINE: \n"
     ]
    }
   ],
   "source": [
    "res_orig=parse_qrc(open(FILENAME+'_orig.txt',encoding='utf-8').read())\n",
    "res_roma=parse_qrc(open(FILENAME+'_roma.txt',encoding='utf-8').read())\n",
    "res_trans=parse_qrc(open(FILENAME+'_trans.txt',encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(res_orig['lines'])==len(res_roma['lines'])==len(res_trans['lines'])\n",
    "L=len(res_orig['lines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res={\n",
    "    'lines': [{\n",
    "        'orig': res_orig['lines'][l],\n",
    "        'roma': res_roma['lines'][l],\n",
    "        'trans': res_trans['lines'][l],\n",
    "    } for l in range(L)],\n",
    "    'time': [[t,None] for t in res_orig['line_time']],\n",
    "    'default_line': {\n",
    "        'orig': [[0,'軌跡 - Roselia']],\n",
    "        'roma': [],\n",
    "        'trans': [[0,'轨迹 - Roselia']],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.json','w') as f:\n",
    "    json.dump(res,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
